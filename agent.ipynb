{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df890d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama_index.core.storage.kvstore.simple_kvstore from index/docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from index/index_store.json.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from constants import embed_model\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"index/\")\n",
    "index = load_index_from_storage(\n",
    "    storage_context, embed_model=embed_model\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "176f5931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import llm_model\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "query_engine = index.as_query_engine(llm=llm_model, similarity_top_k=5)\n",
    "rag_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"research_paper_query_engine_tool\",\n",
    "    description=\"A RAG engine with recent research papers\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85fc539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_prompt_dictionary(prompt_dict):\n",
    "    for key, prompt in prompt_dict.items():\n",
    "        display(Markdown(f\"**Prompt key** {key}\"))\n",
    "        print(prompt.get_template())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "670ebeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt key** response_synthesizer:text_qa_template"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt key** response_synthesizer:refine_template"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    }
   ],
   "source": [
    "prompt_dict = query_engine.get_prompts()\n",
    "display_prompt_dictionary(prompt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7480f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "from tools import download_pdf, fetch_arxiv_papers\n",
    "\n",
    "download_pdf_tool = FunctionTool.from_defaults(\n",
    "    download_pdf,\n",
    "    name=\"download_pdf_file_tool\",\n",
    "    description=\"python function that downloads a pdf file from a url link\"\n",
    ")\n",
    "\n",
    "fetch_arxiv_tool = FunctionTool.from_defaults(\n",
    "    fetch_arxiv_papers,\n",
    "    name=\"fetch_arxiv_papers_tool\",\n",
    "    description=\"downloads the {max_results} recent papers regarding the topic {title} from arXiv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b138c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent \n",
    "\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=[rag_tool, download_pdf_tool, fetch_arxiv_tool],\n",
    "    llm=llm_model,\n",
    "    verbose=True,\n",
    "    max_iterations=6,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b820b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"\n",
    "I am interested in the topic {title} \n",
    "Find papers in your knowlege base relating to this topic.\n",
    "Use the following template to query research_paper_query_engine_tool tool: 'Provide the summary, title, summary authors, and link to download papers related to {title}.'\n",
    "If there are no corresponding papers, fetch the recent ones from arXiv.\n",
    "IMPORTANT: Do not download papers unless the user explicitly asks for it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9394a1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 08d72ac4-af15-4687-95a6-3bf2d0691395. Step input: \n",
      "I am interested in the topic NLP \n",
      "Find papers in your knowlege base relating to this topic.\n",
      "Use the following template to query research_paper_query_engine_tool tool: 'Provide the summary, title, summary authors, and link to download papers related to NLP.'\n",
      "If there are no corresponding papers, fetch the recent ones from arXiv.\n",
      "IMPORTANT: Do not download papers unless the user explicitly asks for it.\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me find papers related to NLP in my knowledge base.\n",
      "Action: research_paper_query_engine_tool\n",
      "Action Input: {'input': 'Provide the summary, title, summary authors, and link to download papers related to NLP.'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Empty Response\n",
      "\u001b[0m> Running step 1298b3f3-de41-4b87-b078-7140c5bd4d4e. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: Since there was no response from the research paper query engine tool, I will fetch recent papers related to NLP from arXiv.\n",
      "Action: fetch_arxiv_papers_tool\n",
      "Action Input: {'title': 'NLP', 'max_results': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: [{'title': 'Reassessing Code Authorship Attribution in the Era of Language Models', 'summary': \"The study of Code Stylometry, and in particular Code Authorship Attribution\\n(CAA), aims to analyze coding styles to identify the authors of code samples.\\nCAA is crucial in cybersecurity and software forensics for addressing,\\ndetecting plagiarism, and supporting criminal prosecutions. However, CAA is a\\ncomplex and error prone task, due to the need for recognizing nuanced\\nrelationships between coding patterns. This challenge is compounded in large\\nsoftware systems with numerous authors due to the subtle variability of\\npatterns that signify the coding style of one author among many. Given the\\nchallenges related to this task, researchers have proposed and studied\\nautomated approaches that rely upon classical Machine Learning and Deep\\nLearning techniques. However, such techniques have historically relied upon\\nhand-crafted features, and due to the often intricate interaction of different\\nfeatures (e.g., formatting, etc.), have key limitations in properly\\ncharacterizing authorship, and are sensitive to adversarial code perturbations.\\nRecently, transformer-based Language Models (LMs) have shown remarkable\\nefficacy across a range of software engineering tasks, and in the authorship\\nattribution on natural language in the NLP domain. However, their effectiveness\\nin CAA is not well understood. As such, we conduct the first extensive\\nempirical study applying two larger state-of-the-art code LMs, and five smaller\\ncode LMs to the task of CAA to 6 diverse datasets that encompass 12k code\\nsnippets written by 463 developers. Furthermore, we perform an in-depth\\nanalysis of our studied models' performance on CAA using established machine\\nlearning interpretability techniques. The results of our analysis illustrate\\nimportant findings that illuminate the behavior of LMs in understanding\\nstylometric code patterns during the task of CAA, and point towards important\\ndirections for future work.\", 'published': '2025-06-20T16:19:30+00:00', 'authors': ['Atish Kumar Dipongkor', 'Ziyu Yao', 'Kevin Moran'], 'journal_ref': None, 'doi': None, 'primary_category': 'cs.SE', 'categories': ['cs.SE'], 'pdf_url': 'http://arxiv.org/pdf/2506.17120v1', 'arxiv_url': 'http://arxiv.org/abs/2506.17120v1'}, {'title': 'eSapiens: A Real-World NLP Framework for Multimodal Document Understanding and Enterprise Knowledge Processing', 'summary': 'We introduce eSapiens, a unified question-answering system designed for\\nenterprise settings, which bridges structured databases and unstructured\\ntextual corpora via a dual-module architecture. The system combines a\\nText-to-SQL planner with a hybrid Retrieval-Augmented Generation (RAG)\\npipeline, enabling natural language access to both relational data and\\nfree-form documents. To enhance answer faithfulness, the RAG module integrates\\ndense and sparse retrieval, commercial reranking, and a citation verification\\nloop that ensures grounding consistency. We evaluate eSapiens on the RAGTruth\\nbenchmark across five leading large language models (LLMs), analyzing\\nperformance across key dimensions such as completeness, hallucination, and\\ncontext utilization. Results demonstrate that eSapiens outperforms a FAISS\\nbaseline in contextual relevance and generation quality, with optional\\nstrict-grounding controls for high-stakes scenarios. This work provides a\\ndeployable framework for robust, citation-aware question answering in\\nreal-world enterprise applications.', 'published': '2025-06-20T06:07:20+00:00', 'authors': ['Isaac Shi', 'Zeyuan Li', 'Wenli Wang', 'Lewei He', 'Yang Yang', 'Tianyu Shi'], 'journal_ref': None, 'doi': None, 'primary_category': 'cs.IR', 'categories': ['cs.IR'], 'pdf_url': 'http://arxiv.org/pdf/2506.16768v1', 'arxiv_url': 'http://arxiv.org/abs/2506.16768v1'}, {'title': 'Initial Investigation of LLM-Assisted Development of Rule-Based Clinical NLP System', 'summary': 'Despite advances in machine learning (ML) and large language models (LLMs),\\nrule-based natural language processing (NLP) systems remain active in clinical\\nsettings due to their interpretability and operational efficiency. However,\\ntheir manual development and maintenance are labor-intensive, particularly in\\ntasks with large linguistic variability. To overcome these limitations, we\\nproposed a novel approach employing LLMs solely during the rule-based systems\\ndevelopment phase. We conducted the initial experiments focusing on the first\\ntwo steps of developing a rule-based NLP pipeline: find relevant snippets from\\nthe clinical note; extract informative keywords from the snippets for the\\nrule-based named entity recognition (NER) component. Our experiments\\ndemonstrated exceptional recall in identifying clinically relevant text\\nsnippets (Deepseek: 0.98, Qwen: 0.99) and 1.0 in extracting key terms for NER.\\nThis study sheds light on a promising new direction for NLP development,\\nenabling semi-automated or automated development of rule-based systems with\\nsignificantly faster, more cost-effective, and transparent execution compared\\nwith deep learning model-based solutions.', 'published': '2025-06-19T21:55:33+00:00', 'authors': ['Jianlin Shi', 'Brian T. Bucher'], 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.LG'], 'pdf_url': 'http://arxiv.org/pdf/2506.16628v1', 'arxiv_url': 'http://arxiv.org/abs/2506.16628v1'}, {'title': 'Modeling Public Perceptions of Science in Media', 'summary': \"Effectively engaging the public with science is vital for fostering trust and\\nunderstanding in our scientific community. Yet, with an ever-growing volume of\\ninformation, science communicators struggle to anticipate how audiences will\\nperceive and interact with scientific news. In this paper, we introduce a\\ncomputational framework that models public perception across twelve dimensions,\\nsuch as newsworthiness, importance, and surprisingness. Using this framework,\\nwe create a large-scale science news perception dataset with 10,489 annotations\\nfrom 2,101 participants from diverse US and UK populations, providing valuable\\ninsights into public responses to scientific information across domains. We\\nfurther develop NLP models that predict public perception scores with a strong\\nperformance. Leveraging the dataset and model, we examine public perception of\\nscience from two perspectives: (1) Perception as an outcome: What factors\\naffect the public perception of scientific information? (2) Perception as a\\npredictor: Can we use the estimated perceptions to predict public engagement\\nwith science? We find that individuals' frequency of science news consumption\\nis the driver of perception, whereas demographic factors exert minimal\\ninfluence. More importantly, through a large-scale analysis and carefully\\ndesigned natural experiment on Reddit, we demonstrate that the estimated public\\nperception of scientific information has direct connections with the final\\nengagement pattern. Posts with more positive perception scores receive\\nsignificantly more comments and upvotes, which is consistent across different\\nscientific information and for the same science, but are framed differently.\\nOverall, this research underscores the importance of nuanced perception\\nmodeling in science communication, offering new pathways to predict public\\ninterest and engagement with scientific content.\", 'published': '2025-06-19T21:49:28+00:00', 'authors': ['Jiaxin Pei', 'Dustin Wright', 'Isabelle Augenstin', 'David Jurgens'], 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.AI', 'cs.CY', 'cs.HC'], 'pdf_url': 'http://arxiv.org/pdf/2506.16622v1', 'arxiv_url': 'http://arxiv.org/abs/2506.16622v1'}, {'title': 'Do We Talk to Robots Like Therapists, and Do They Respond Accordingly? Language Alignment in AI Emotional Support', 'summary': \"As conversational agents increasingly engage in emotionally supportive\\ndialogue, it is important to understand how closely their interactions resemble\\nthose in traditional therapy settings. This study investigates whether the\\nconcerns shared with a robot align with those shared in human-to-human (H2H)\\ntherapy sessions, and whether robot responses semantically mirror those of\\nhuman therapists. We analyzed two datasets: one of interactions between users\\nand professional therapists (Hugging Face's NLP Mental Health Conversations),\\nand another involving supportive conversations with a social robot (QTrobot\\nfrom LuxAI) powered by a large language model (LLM, GPT-3.5). Using sentence\\nembeddings and K-means clustering, we assessed cross-agent thematic alignment\\nby applying a distance-based cluster-fitting method that evaluates whether\\nresponses from one agent type map to clusters derived from the other, and\\nvalidated it using Euclidean distances. Results showed that 90.88% of robot\\nconversation disclosures could be mapped to clusters from the human therapy\\ndataset, suggesting shared topical structure. For matched clusters, we compared\\nthe subjects as well as therapist and robot responses using Transformer,\\nWord2Vec, and BERT embeddings, revealing strong semantic overlap in subjects'\\ndisclosures in both datasets, as well as in the responses given to similar\\nhuman disclosure themes across agent types (robot vs. human therapist). These\\nfindings highlight both the parallels and boundaries of robot-led support\\nconversations and their potential for augmenting mental health interventions.\", 'published': '2025-06-19T17:20:30+00:00', 'authors': ['Sophie Chiang', 'Guy Laban', 'Hatice Gunes'], 'journal_ref': None, 'doi': None, 'primary_category': 'cs.HC', 'categories': ['cs.HC', 'cs.AI', 'cs.CL'], 'pdf_url': 'http://arxiv.org/pdf/2506.16473v1', 'arxiv_url': 'http://arxiv.org/abs/2506.16473v1'}]\n",
      "\u001b[0m> Running step 5c9f04ed-ea42-4805-ba75-e6d5338f6aec. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have found recent papers related to NLP from arXiv. I will now provide the summaries, titles, authors, and links to these papers.\n",
      "Answer: 1. **Title**: Reassessing Code Authorship Attribution in the Era of Language Models\n",
      "   - **Authors**: Atish Kumar Dipongkor, Ziyu Yao, Kevin Moran\n",
      "   - **Summary**: This paper explores Code Authorship Attribution (CAA) using transformer-based Language Models (LMs) on diverse datasets. It highlights the challenges and effectiveness of LMs in understanding stylometric code patterns.\n",
      "   - **Link**: [PDF](http://arxiv.org/pdf/2506.17120v1)\n",
      "\n",
      "2. **Title**: eSapiens: A Real-World NLP Framework for Multimodal Document Understanding and Enterprise Knowledge Processing\n",
      "   - **Authors**: Isaac Shi, Zeyuan Li, Wenli Wang, Lewei He, Yang Yang, Tianyu Shi\n",
      "   - **Summary**: eSapiens is a question-answering system for enterprise settings, integrating structured databases and unstructured textual corpora. It outperforms baselines in contextual relevance and generation quality.\n",
      "   - **Link**: [PDF](http://arxiv.org/pdf/2506.16768v1)\n",
      "\n",
      "3. **Title**: Initial Investigation of LLM-Assisted Development of Rule-Based Clinical NLP System\n",
      "   - **Authors**: Jianlin Shi, Brian T. Bucher\n",
      "   - **Summary**: This study proposes using LLMs in developing rule-based NLP systems for clinical settings, demonstrating high recall in identifying relevant text snippets and extracting key terms.\n",
      "   - **Link**: [PDF](http://arxiv.org/pdf/2506.16628v1)\n",
      "\n",
      "4. **Title**: Modeling Public Perceptions of Science in Media\n",
      "   - **Authors**: Jiaxin Pei, Dustin Wright, Isabelle Augenstin, David Jurgens\n",
      "   - **Summary**: The paper introduces a framework for modeling public perception of science in media, using NLP models to predict public engagement with scientific content.\n",
      "   - **Link**: [PDF](http://arxiv.org/pdf/2506.16622v1)\n",
      "\n",
      "5. **Title**: Do We Talk to Robots Like Therapists, and Do They Respond Accordingly? Language Alignment in AI Emotional Support\n",
      "   - **Authors**: Sophie Chiang, Guy Laban, Hatice Gunes\n",
      "   - **Summary**: This study examines the thematic alignment between robot and human therapist interactions, finding strong semantic overlap in subjects' disclosures and responses.\n",
      "   - **Link**: [PDF](http://arxiv.org/pdf/2506.16473v1)\n",
      "\n",
      "If you need more information or wish to download any of these papers, please let me know!\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "answer = agent.chat(query_template.format(title=\"NLP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75869ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. **Title**: Reassessing Code Authorship Attribution in the Era of Language Models\n",
       "   - **Authors**: Atish Kumar Dipongkor, Ziyu Yao, Kevin Moran\n",
       "   - **Summary**: This paper explores Code Authorship Attribution (CAA) using transformer-based Language Models (LMs) on diverse datasets. It highlights the challenges and effectiveness of LMs in understanding stylometric code patterns.\n",
       "   - **Link**: [PDF](http://arxiv.org/pdf/2506.17120v1)\n",
       "\n",
       "2. **Title**: eSapiens: A Real-World NLP Framework for Multimodal Document Understanding and Enterprise Knowledge Processing\n",
       "   - **Authors**: Isaac Shi, Zeyuan Li, Wenli Wang, Lewei He, Yang Yang, Tianyu Shi\n",
       "   - **Summary**: eSapiens is a question-answering system for enterprise settings, integrating structured databases and unstructured textual corpora. It outperforms baselines in contextual relevance and generation quality.\n",
       "   - **Link**: [PDF](http://arxiv.org/pdf/2506.16768v1)\n",
       "\n",
       "3. **Title**: Initial Investigation of LLM-Assisted Development of Rule-Based Clinical NLP System\n",
       "   - **Authors**: Jianlin Shi, Brian T. Bucher\n",
       "   - **Summary**: This study proposes using LLMs in developing rule-based NLP systems for clinical settings, demonstrating high recall in identifying relevant text snippets and extracting key terms.\n",
       "   - **Link**: [PDF](http://arxiv.org/pdf/2506.16628v1)\n",
       "\n",
       "4. **Title**: Modeling Public Perceptions of Science in Media\n",
       "   - **Authors**: Jiaxin Pei, Dustin Wright, Isabelle Augenstin, David Jurgens\n",
       "   - **Summary**: The paper introduces a framework for modeling public perception of science in media, using NLP models to predict public engagement with scientific content.\n",
       "   - **Link**: [PDF](http://arxiv.org/pdf/2506.16622v1)\n",
       "\n",
       "5. **Title**: Do We Talk to Robots Like Therapists, and Do They Respond Accordingly? Language Alignment in AI Emotional Support\n",
       "   - **Authors**: Sophie Chiang, Guy Laban, Hatice Gunes\n",
       "   - **Summary**: This study examines the thematic alignment between robot and human therapist interactions, finding strong semantic overlap in subjects' disclosures and responses.\n",
       "   - **Link**: [PDF](http://arxiv.org/pdf/2506.16473v1)\n",
       "\n",
       "If you need more information or wish to download any of these papers, please let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(answer.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2ed90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_query_template = \"\"\"Download the following papers:\n",
    "for each paper:\n",
    "1. Process one paper at a time\n",
    "2. State which paper number you are processing out of the total number of papers\n",
    "3. Complete a full download cycle before moving to the next paper\n",
    "4. Explicitely state when moving to the next paper\n",
    "5. Provide a final summary only when all papers are downloaded\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d7388",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    agent.chat(download_query_template)\n",
    "except Exception as e:\n",
    "    if \"max iterations\" in str(e).lower():\n",
    "        print(\"Error: Maximum number of iterations reached.\")\n",
    "    else:\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv-ai-agent-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
